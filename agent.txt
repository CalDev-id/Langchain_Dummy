ðŸ”¹ Daftar AgentType Populer di LangChain
1. ZERO_SHOT_REACT_DESCRIPTION
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION
)
Default / klasik.
Agent pakai prompt ReAct (Reasoning + Acting).
Gunakan deskripsi tool untuk memutuskan tool mana yang dipakai.
Contoh: "Gunakan Search untuk mencari berita terbaru".
2. CHAT_ZERO_SHOT_REACT_DESCRIPTION
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION
)
Mirip ZERO_SHOT_REACT_DESCRIPTION, tapi lebih cocok untuk model chat (seperti LLaMA, GPT).
Output lebih natural, biasanya direkomendasikan kalau pakai ChatGroq atau ChatOpenAI.
3. CONVERSATIONAL_REACT_DESCRIPTION
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
    memory=ConversationBufferMemory()
)
Sama seperti CHAT_ZERO_SHOT_REACT_DESCRIPTION tapi dengan memory percakapan.
Jadi bisa nyambung:
Kamu: â€œSiapa presiden Indonesia?â€
Agent: â€œJoko Widodo.â€
Kamu: â€œUmurnya berapa dikali 3?â€
Agent: inget konteks bahwa â€œumurnyaâ€ = Jokowi.
4. STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION
)
Sama dengan chat agent, tapi structured â†’ LLM menghasilkan JSON-like output untuk memilih tool.
Lebih aman karena LLM dipaksa memilih dengan format tertentu.
Cocok kalau kamu punya banyak tools, supaya nggak ngawur pilihannya.
5. OPENAI_FUNCTIONS (atau create_openai_functions_agent)
agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.OPENAI_FUNCTIONS
)
Agent yang pakai function calling (mirip OpenAI GPT-4 Function Calling).
Kalau LLM mendukung format function call â†’ bisa memanggil tool langsung tanpa prompt hack.
Di Groq, ini tergantung apakah model support format function-call. Kalau enggak, lebih aman pakai STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION.
ðŸ”¹ Rekomendasi Buat Kamu (pakai Groq LLaMA)
Kalau eksperimen awal â†’ pakai CHAT_ZERO_SHOT_REACT_DESCRIPTION.
Kalau butuh multi-turn dengan memory â†’ pakai CONVERSATIONAL_REACT_DESCRIPTION.
Kalau punya banyak tools dan mau output rapi â†’ pakai STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION.



Kalau fungsi yang kamu buat butuh lebih dari 1 parameter, biasanya ada 2 cara dalam LangChain:
âœ… 1. Terima str lalu parse di dalam fungsi
Contoh:
def tambah(a: int, b: int):
    return a + b

def add_numbers(x: str):
    # asumsikan input selalu dalam format "angka1, angka2"
    parts = x.split(",")
    a, b = int(parts[0].strip()), int(parts[1].strip())
    return tambah(a, b)

tool = Tool(
    name="Adder",
    func=add_numbers,
    description="Gunakan untuk menjumlahkan dua angka. Format input: 'angka1, angka2'."
)
Agent akan kasih string "5, 7", lalu fungsi akan parse jadi (5,7) â†’ hasil 12.
Ini cara paling umum karena LLM suka pakai teks biasa.
âœ… 2. Pakai StructuredTool (lebih rapi, param-nya jelas)
Kalau kamu pakai LangChain yang agak baru, ada StructuredTool (atau @tool decorator) yang bisa langsung definisikan parameter kaya API.
Contoh:
from langchain.tools import StructuredTool

def bagi(a: float, b: float) -> float:
    """Membagi angka a dengan b."""
    return a / b

bagi_tool = StructuredTool.from_function(bagi)
Nanti agent tahu bagi butuh a dan b, bukan sekadar str.
Kalau dipanggil, agent bisa kasih input seperti:
Action: bagi
Action Input: {"a": 10, "b": 2}
dan LangChain akan otomatis map ke bagi(10,2) â†’ hasil 5.